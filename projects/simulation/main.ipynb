{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af890f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation.sim_utils import RandomSimulator\n",
    "from utils.core.save_manager import SaveUtils\n",
    "from utils.data_io import load_data\n",
    "import os\n",
    "from utils.eda.visualisation.general_viz import Visualisation\n",
    "from utils.eda.correlation import CorrelationAnalyzer\n",
    "import pandas as pd\n",
    "from utils.simulation.decomposition import Decomposer\n",
    "from utils.simulation.covariance_matrix import CovarianceMatrix\n",
    "from utils.simulation.monte_carlo_simulator import MonteCarloSimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b3aab",
   "metadata": {},
   "source": [
    "ðŸ§ª Simulating Unscaled Normally Distributed Data with Specified Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51eb0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to c:\\Data Science Projects\\Daanish\\projects\\simulation\\data/output/simulated_normal.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "simulator = RandomSimulator(num_simulations=1000)\n",
    "df = simulator.simulate_normal(num_variables=10, target_skew=0, target_kurt=3)\n",
    "\n",
    "save_util = SaveUtils()\n",
    "save_util.save_dataframe_to_csv(df,os.path.join(os.getcwd(), \"data/output/simulated_normal.csv\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446deb3",
   "metadata": {},
   "source": [
    "ðŸ§ª Simulate scaled normals (e.g., volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5180ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [0.2, 0.15, 0.3]  # std devs or volatilities\n",
    "# simulator = RandomSimulator(parameters=params)\n",
    "# df = simulator.simulate_normal(target_skew=0, target_kurt=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b1844",
   "metadata": {},
   "source": [
    "ðŸ“Š Simulating Poisson Data from Excel Input\n",
    "- Reads input data from an Excel file\n",
    "- Initializes a Poisson simulator\n",
    "- Simulates Poisson-distributed values\n",
    "- Saves the simulated data to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7b23ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved to c:\\Data Science Projects\\Daanish\\projects\\simulation\\data/output/simulated_poisson.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "df = load_data(\n",
    "    source_type='excel',\n",
    "    input_path= os.path.join(os.getcwd(), \"data/input/Poisson Simulation.xlsx\"),\n",
    "    sheet_name='Lambda Calculation',\n",
    "    usecols=['Lambda']\n",
    ")\n",
    "simulator = RandomSimulator(parameters=df['Lambda'],num_simulations = 10000)\n",
    "sim = simulator.simulate_poisson()\n",
    "save_util.save_dataframe_to_excel(\n",
    "    sim,\n",
    "    os.path.join(os.getcwd(), \"data/output/simulated_poisson.xlsx\"),\n",
    "    sheet_name=\"simulated values\", \n",
    "    overwrite=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46077bcd",
   "metadata": {},
   "source": [
    "#### ðŸ”— 2.5 Examine Variable Correlations\n",
    "\n",
    "This section calculates and displays correlations between different types of variables in the `main_df`.\n",
    "\n",
    "- **`num_method` (str)**: Defines the method for calculating correlation between numerical variables. Allowed values are:\n",
    "    - `'pearson'` *(default)*: Standard Pearson linear correlation coefficient.\n",
    "    - `'spearman'`: Spearman's rank correlation coefficient (for monotonic relationships).\n",
    "    - `'kendall'`: Kendall's tau correlation coefficient (for ordinal or non-normally distributed data).\n",
    "\n",
    "- **`cat_method` (str)**: Defines the method for calculating association between categorical variables. Allowed values are:\n",
    "    - `'cramers_v'` *(default)*: Cramer's V (measures association between nominal categorical variables).\n",
    "    - `'mutual_info'`: Mutual Information (measures the statistical dependence between two random variables).\n",
    "\n",
    "- **`cat_num_method` (str)**: Defines the method for calculating association between categorical and numerical variables. Allowed values are:\n",
    "    - `'correlation_ratio'` *(default)*: Correlation Ratio (Eta squared, measures variance explained).\n",
    "    - `'f_test'`: F-statistic from ANOVA (assesses the difference in means across categories).\n",
    "    - `'mutual_info'`: Mutual Information (measures the statistical dependence). \n",
    "    - `'kruskal'`: Non-parametric alternative to ANOVA. Compares distributions of a continuous variable across categories. Good when your numerical variables are not normally distributed\n",
    "    - `'target_spearman'`: Replaces each category with the mean of the target variable (e.g. default rate). Then computes correlation with numerical features. Captures ordinal structure or monotonic trends across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442545c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = load_data(\n",
    "    source_type='csv',\n",
    "    input_path= os.path.join(os.getcwd(), \"data/input/Correlation Analysis - Raw Data.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be3069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = CorrelationAnalyzer(main_df)\n",
    "corr_df,corr_matrix = analyzer.correlation_matrix(num_method=\"spearman\", cat_method=\"cramers_v\",\n",
    "                                      cat_num_method=\"correlation_ratio\",return_matrix=True)\n",
    "\n",
    "# Visualisation.plot_heatmap_matrix(corr_matrix, title=\"Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14465ce8",
   "metadata": {},
   "source": [
    "CovarianceMatrix\n",
    "----------------\n",
    "A utility class for calculating the covariance matrix of asset returns,\n",
    "optionally annualized. Intended for use in financial simulations such as\n",
    "Monte Carlo modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435a8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_calc = CovarianceMatrix(main_df)\n",
    "cov_matrix = cov_calc.get_matrix()\n",
    "# print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e06c9d",
   "metadata": {},
   "source": [
    "#### Cholesky Decomposition and Visualisation\n",
    "\n",
    "We perform a Cholesky decomposition on the correlation matrix to obtain a lower triangular matrix.  \n",
    "This decomposition is useful for simulations and generating correlated random variables.  \n",
    "We then visualise the resulting matrix using a heatmap for better interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d08a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decomposition_df = Decomposer.cholesky_decomposition(cov_matrix)\n",
    "# Visualisation.plot_heatmap_matrix(Decomposition_df, title=\"Cholesky Decomposition Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194353f",
   "metadata": {},
   "source": [
    "##### ðŸ“Š Monte Carlo Simulation Using Rubinstein's Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc80b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      5\u001b[39m main_df = load_data(\n\u001b[32m      6\u001b[39m     source_type=\u001b[33m'\u001b[39m\u001b[33mcsv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     input_path= os.path.join(os.getcwd(), \u001b[33m\"\u001b[39m\u001b[33mdata/input/Monte Carlo Univariable.csv\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m sim = MonteCarloSimulator(main_df,num_simulations=\u001b[32m10000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43msim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m multivariate_MC_simulation = sim.get_final_simulated_values()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# covariance_matrix = sim.get_covariance_matrix()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Data Science Projects\\Daanish\\utils\\simulation\\monte_carlo_simulator.py:74\u001b[39m, in \u001b[36mMonteCarloSimulator.run_simulation\u001b[39m\u001b[34m(self, skew, kurt)\u001b[39m\n\u001b[32m     71\u001b[39m std = \u001b[38;5;28mself\u001b[39m.data[variable].std()\n\u001b[32m     72\u001b[39m mean = \u001b[38;5;28mself\u001b[39m.data[variable].mean()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28mself\u001b[39m.simulated_raw = \u001b[43msimulator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimulate_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_skew\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_kurt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkurt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.simulated_raw.columns = [variable]\n\u001b[32m     80\u001b[39m \u001b[38;5;28mself\u001b[39m.simulated_final = \u001b[38;5;28mself\u001b[39m.simulated_raw * std + mean\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Data Science Projects\\Daanish\\utils\\simulation\\sim_utils.py:74\u001b[39m, in \u001b[36mRandomSimulator.simulate_normal\u001b[39m\u001b[34m(self, target_skew, target_kurt, num_variables)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mProvide either `parameters` or `num_variables` for normal simulation.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m random_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_uncorrelated_random\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_skew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_kurt\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# If parameters are provided, scale the results by parameters (e.g., standard deviations, volatilities, etc.)\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Data Science Projects\\Daanish\\utils\\simulation\\sim_utils.py:115\u001b[39m, in \u001b[36mRandomSimulator._generate_uncorrelated_random\u001b[39m\u001b[34m(self, num_samples, num_variables, target_skew, target_kurt)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Decorrelate\u001b[39;00m\n\u001b[32m    114\u001b[39m cov_matrix = np.cov(random_numbers, rowvar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m eigenvalues, eigenvectors = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m decorrelated = random_numbers @ eigenvectors @ np.diag(\n\u001b[32m    117\u001b[39m     \u001b[32m1\u001b[39m / np.sqrt(eigenvalues)) @ eigenvectors.T\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_variables):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<__array_function__ internals>:200\u001b[39m, in \u001b[36meigh\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1439\u001b[39m, in \u001b[36meigh\u001b[39m\u001b[34m(a, UPLO)\u001b[39m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUPLO argument must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mL\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mU\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1438\u001b[39m a, wrap = _makearray(a)\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m \u001b[43m_assert_stacked_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m _assert_stacked_square(a)\n\u001b[32m   1441\u001b[39m t, result_t = _commonType(a)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:183\u001b[39m, in \u001b[36m_assert_stacked_2d\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m a.ndim < \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m-dimensional array given. Array must be \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    184\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mat least two-dimensional\u001b[39m\u001b[33m'\u001b[39m % a.ndim)\n",
      "\u001b[31mLinAlgError\u001b[39m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "# main_df = load_data(\n",
    "#     source_type='csv',\n",
    "#     input_path= os.path.join(os.getcwd(), \"data/input/Monte Carlo Multivariable.csv\"),\n",
    "# )\n",
    "main_df = load_data(\n",
    "    source_type='csv',\n",
    "    input_path= os.path.join(os.getcwd(), \"data/input/Monte Carlo Univariable.csv\"),\n",
    ")\n",
    "\n",
    "sim = MonteCarloSimulator(main_df,num_simulations=10000)\n",
    "sim.run_simulation()\n",
    "multivariate_MC_simulation = sim.get_final_simulated_values()\n",
    "# covariance_matrix = sim.get_covariance_matrix()\n",
    "raw_normal_simulation = sim.get_raw_simulations()\n",
    "# cholesky_matrix = sim.get_cholesky_matrix()\n",
    "\n",
    "save_util.save_dataframe_to_csv(\n",
    "    multivariate_MC_simulation,\n",
    "    os.path.join(os.getcwd(), \"data/output/MonteCarlo final_sim_u.csv\"),\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "save_util.save_dataframe_to_csv(\n",
    "    raw_normal_simulation,\n",
    "    os.path.join(os.getcwd(), \"data/output/MonteCarlo random_sim_u.csv\"),\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "# save_util.save_dataframe_to_csv(\n",
    "#     covariance_matrix,\n",
    "#     os.path.join(os.getcwd(), \"data/output/MonteCarlo cov_matrix.csv\"),\n",
    "#     overwrite=True\n",
    "#     )\n",
    "\n",
    "\n",
    "# save_util.save_dataframe_to_csv(\n",
    "#     cholesky_matrix,\n",
    "#     os.path.join(os.getcwd(), \"data/output/MonteCarlo cholesky_matrix.csv\"),\n",
    "#     overwrite=True\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
