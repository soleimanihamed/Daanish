{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af890f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simulation.sim_utils import RandomSimulator\n",
    "from utils.core.save_manager import SaveUtils\n",
    "from utils.data_io import load_data\n",
    "import os\n",
    "from utils.viz.general_viz import Visualisation\n",
    "from utils.eda.correlation import CorrelationAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.simulation.decomposition import Decomposer\n",
    "from utils.simulation.covariance_matrix import CovarianceMatrix\n",
    "from utils.simulation.monte_carlo_simulator import MonteCarloSimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b3aab",
   "metadata": {},
   "source": [
    "ðŸ§ª Simulating Unscaled Normally Distributed Data with Specified Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_column_names = [\n",
    "    \"Interest_Rate\", \"Loan_Amount\", \"Employment_Length\",\n",
    "    \"Age\", \"Income\", \"Credit_Score\",\n",
    "    \"Debt_To_Income\", \"Home_Ownership\", \"Purpose\", \"Region\"\n",
    "]\n",
    "\n",
    "simulator = RandomSimulator(num_simulations=1000,column_names=custom_column_names)\n",
    "df = simulator.simulate_normal(num_variables=10, target_skew=0, target_kurt=3)\n",
    "\n",
    "save_util = SaveUtils()\n",
    "save_util.save_dataframe_to_csv(df,os.path.join(os.getcwd(), \"data/output/simulated_normal.csv\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446deb3",
   "metadata": {},
   "source": [
    "ðŸ§ª Simulate scaled normals (e.g., volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5180ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [0.2, 0.15, 0.3]  # std devs or volatilities\n",
    "# simulator = RandomSimulator(parameters=params)\n",
    "# df = simulator.simulate_normal(target_skew=0, target_kurt=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b1844",
   "metadata": {},
   "source": [
    "ðŸ“Š Simulating Poisson Data from Excel Input\n",
    "- Reads input data from an Excel file\n",
    "- Initializes a Poisson simulator\n",
    "- Simulates Poisson-distributed values\n",
    "- Saves the simulated data to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input  = load_data(\n",
    "    source_type='excel',\n",
    "    input_path= os.path.join(os.getcwd(), \"data/input/Poisson Simulation.xlsx\"),\n",
    "    sheet_name='Lambda Calculation',\n",
    "    usecols=['Class','Lambda']\n",
    ")\n",
    "parameters = df_input[\"Lambda\"].values\n",
    "column_names = [f\"Class_{int(c)}\" for c in df_input[\"Class\"].values]\n",
    "\n",
    "simulator = RandomSimulator(parameters=parameters, column_names=column_names,num_simulations = 10000)\n",
    "sim = simulator.simulate_poisson()\n",
    "df_poisson = sim.round().astype(int)\n",
    "save_util.save_dataframe_to_excel(\n",
    "    df_poisson,\n",
    "    os.path.join(os.getcwd(), \"data/output/simulated_poisson.xlsx\"),\n",
    "    sheet_name=\"simulated values\", \n",
    "    overwrite=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46077bcd",
   "metadata": {},
   "source": [
    "#### ðŸ”— 2.5 Examine Variable Correlations\n",
    "\n",
    "This section calculates and displays correlations between different types of variables in the `main_df`.\n",
    "\n",
    "- **`num_method` (str)**: Defines the method for calculating correlation between numerical variables. Allowed values are:\n",
    "    - `'pearson'` *(default)*: Standard Pearson linear correlation coefficient.\n",
    "    - `'spearman'`: Spearman's rank correlation coefficient (for monotonic relationships).\n",
    "    - `'kendall'`: Kendall's tau correlation coefficient (for ordinal or non-normally distributed data).\n",
    "\n",
    "- **`cat_method` (str)**: Defines the method for calculating association between categorical variables. Allowed values are:\n",
    "    - `'cramers_v'` *(default)*: Cramer's V (measures association between nominal categorical variables).\n",
    "    - `'mutual_info'`: Mutual Information (measures the statistical dependence between two random variables).\n",
    "\n",
    "- **`cat_num_method` (str)**: Defines the method for calculating association between categorical and numerical variables. Allowed values are:\n",
    "    - `'correlation_ratio'` *(default)*: Correlation Ratio (Eta squared, measures variance explained).\n",
    "    - `'f_test'`: F-statistic from ANOVA (assesses the difference in means across categories).\n",
    "    - `'mutual_info'`: Mutual Information (measures the statistical dependence). \n",
    "    - `'kruskal'`: Non-parametric alternative to ANOVA. Compares distributions of a continuous variable across categories. Good when your numerical variables are not normally distributed\n",
    "    - `'target_spearman'`: Replaces each category with the mean of the target variable (e.g. default rate). Then computes correlation with numerical features. Captures ordinal structure or monotonic trends across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442545c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = load_data(\n",
    "    source_type='csv',\n",
    "    input_path= os.path.join(os.getcwd(), \"data/input/returns_raw.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = CorrelationAnalyzer(main_df)\n",
    "corr_df,corr_matrix = analyzer.correlation_matrix(num_method=\"pearson\", cat_method=\"cramers_v\",\n",
    "                                      cat_num_method=\"correlation_ratio\",return_matrix=True)\n",
    "\n",
    "Visualisation.plot_heatmap_matrix(corr_matrix, title=\"Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14465ce8",
   "metadata": {},
   "source": [
    "CovarianceMatrix\n",
    "----------------\n",
    "A utility class for calculating the covariance matrix of asset returns,\n",
    "optionally annualized. Intended for use in financial simulations such as\n",
    "Monte Carlo modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_calc = CovarianceMatrix(main_df)\n",
    "cov_matrix = cov_calc.get_matrix()\n",
    "# print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e06c9d",
   "metadata": {},
   "source": [
    "#### Cholesky Decomposition and Visualisation\n",
    "\n",
    "We perform a Cholesky decomposition on the correlation matrix to obtain a lower triangular matrix.  \n",
    "This decomposition is useful for simulations and generating correlated random variables.  \n",
    "We then visualise the resulting matrix using a heatmap for better interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d08a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decomposition_df = Decomposer.cholesky_decomposition(cov_matrix)\n",
    "# Visualisation.plot_heatmap_matrix(Decomposition_df, title=\"Cholesky Decomposition Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194353f",
   "metadata": {},
   "source": [
    "##### ðŸ“Š Monte Carlo Simulation Using Rubinstein's Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc80b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df = load_data(\n",
    "#     source_type='csv',\n",
    "#     input_path= os.path.join(os.getcwd(), \"data/input/Monte Carlo Multivariable.csv\"),\n",
    "# )\n",
    "main_df = load_data(\n",
    "    source_type='csv',\n",
    "    input_path= os.path.join(os.getcwd(), \"data/input/Monte Carlo Univariable.csv\"),\n",
    ")\n",
    "\n",
    "sim = MonteCarloSimulator(main_df,num_simulations=10000)\n",
    "sim.run_simulation()\n",
    "multivariate_MC_simulation = sim.get_final_simulated_values()\n",
    "# covariance_matrix = sim.get_covariance_matrix()\n",
    "raw_normal_simulation = sim.get_raw_simulations()\n",
    "# cholesky_matrix = sim.get_cholesky_matrix()\n",
    "\n",
    "save_util.save_dataframe_to_csv(\n",
    "    multivariate_MC_simulation,\n",
    "    os.path.join(os.getcwd(), \"data/output/MonteCarlo final_sim_u.csv\"),\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "save_util.save_dataframe_to_csv(\n",
    "    raw_normal_simulation,\n",
    "    os.path.join(os.getcwd(), \"data/output/MonteCarlo random_sim_u.csv\"),\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "# save_util.save_dataframe_to_csv(\n",
    "#     covariance_matrix,\n",
    "#     os.path.join(os.getcwd(), \"data/output/MonteCarlo cov_matrix.csv\"),\n",
    "#     overwrite=True\n",
    "#     )\n",
    "\n",
    "\n",
    "# save_util.save_dataframe_to_csv(\n",
    "#     cholesky_matrix,\n",
    "#     os.path.join(os.getcwd(), \"data/output/MonteCarlo cholesky_matrix.csv\"),\n",
    "#     overwrite=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24676862",
   "metadata": {},
   "source": [
    "Reading From a Json Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d23b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_io import load_data\n",
    "api_data = '[[\"name\", \"age\"], [\"Alice\", 30], [\"Bob\", 25]]'\n",
    "df = load_data(source_type='json', json_source=api_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a6741",
   "metadata": {},
   "source": [
    "Fitting **Beta** distributions and then simulating random numbers based on the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741599e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eda.statistical import StatisticalAnalysis\n",
    "from utils.simulation.sim_utils import RandomSimulator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Create sample dataframe with random numbers between 0 and 1\n",
    "np.random.seed(42)  # for reproducibility\n",
    "df = pd.DataFrame({\n",
    "    'default_rate': np.random.rand(100)\n",
    "})\n",
    "\n",
    "\n",
    "# Step 2: Initialize StatisticalAnalysis\n",
    "stat = StatisticalAnalysis(df)\n",
    "\n",
    "# Step 3: Fit only 'beta' and 'logit-normal'\n",
    "distribution_results = stat.fit_best_distribution(\n",
    "    ['default_rate'],\n",
    "    method='sumsquare_error',\n",
    "    common_distributions=False,\n",
    "    distribution_list=['beta'],  # assuming 'logitnorm' works with Fitter\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "print(\"\\nReturned Results:\", distribution_results)\n",
    "\n",
    "\n",
    "params = distribution_results['default_rate']['parameters']\n",
    "simulator = RandomSimulator(\n",
    "    parameters=[(params['a'], params['b'], params['loc'], params['scale'])],\n",
    "    num_simulations=10000,\n",
    "    column_names=['default_rate_sim']\n",
    ")\n",
    "df_sim = simulator.simulate_beta()\n",
    "print(df_sim.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ca765",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab99740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eda.statistical import StatisticalAnalysis\n",
    "from utils.simulation.sim_utils import RandomSimulator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create sample dataframe\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'default_rate': np.random.randint(100, 1001, size=100)  # 100 integers from 100 to 1000 inclusive\n",
    "})\n",
    "\n",
    "# Step 2: Initialize StatisticalAnalysis\n",
    "stat = StatisticalAnalysis(df)\n",
    "\n",
    "# Step 3: Fit only 'logit-normal' and 'gamma'\n",
    "distribution_results = stat.fit_best_distribution(\n",
    "    ['default_rate'],\n",
    "    method='sumsquare_error',\n",
    "    common_distributions=False,\n",
    "    distribution_list=['lognorm', 'gamma'],\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "print(\"\\nReturned Results:\", distribution_results)\n",
    "\n",
    "# Step 4: Loop through results and simulate using the winning distribution\n",
    "for col, res in distribution_results.items():\n",
    "    best_dist = res['best_distribution']   # e.g., 'lognorm' or 'gamma'\n",
    "    params = res['parameters']\n",
    "\n",
    "    simulator = RandomSimulator(\n",
    "        parameters=[tuple(params.values())],  # convert dict to tuple\n",
    "        num_simulations=10000,\n",
    "        column_names=[f\"{col}_sim\"]\n",
    "    )\n",
    "\n",
    "    if best_dist == 'lognorm':\n",
    "        ordered_params = (params['s'], params['loc'], params['scale'])\n",
    "        simulator = RandomSimulator(\n",
    "            parameters=[ordered_params],\n",
    "            num_simulations=10000,\n",
    "            column_names=[f\"{col}_sim\"]\n",
    "        )\n",
    "        df_sim = simulator.simulate_lognormal()\n",
    "    elif best_dist == 'gamma':\n",
    "        ordered_params = (params['a'], params['loc'], params['scale'])\n",
    "        simulator = RandomSimulator(\n",
    "            parameters=[ordered_params],\n",
    "            num_simulations=10000,\n",
    "            column_names=[f\"{col}_sim\"]\n",
    "        )\n",
    "        df_sim = simulator.simulate_gamma()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported distribution: {best_dist}\")\n",
    "\n",
    "    print(f\"\\nSimulation for {col} ({best_dist}):\")\n",
    "    print(df_sim.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
